{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jX4BxWqGDzJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085bd5e5-b7d1-4174-b2ae-ff7f868adcbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Скачали и Загрузили данные:: \n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "2. Исключили лишние признаки:: \n",
            "   Pclass  Sex   Age     Fare Embarked\n",
            "0       3    0  22.0   7.2500        S\n",
            "1       1    1  38.0  71.2833        C\n",
            "2       3    1  26.0   7.9250        S\n",
            "3       1    1  35.0  53.1000        S\n",
            "4       3    0  35.0   8.0500        S\n",
            "\n",
            "3. Разделили выборку:: \n",
            "712\n",
            "179\n",
            "\n",
            "4. Преобразовали категориальные и некатегориальные признаки:: \n",
            "[[-3.66149543e-01 -3.43781337e-02  0.00000000e+00 ...  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00]\n",
            " [-8.31398553e-01  4.09404995e-01  1.00000000e+00 ...  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00]\n",
            " [-1.77290341e-03 -4.56068163e-01  0.00000000e+00 ...  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00]\n",
            " ...\n",
            " [ 4.09265475e-01 -4.09000255e-01  1.00000000e+00 ...  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00]\n",
            " [-2.14960408e+00  1.51732215e-01  1.00000000e+00 ...  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00]\n",
            " [ 7.96972984e-01 -7.81647357e-02  1.00000000e+00 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1. Скачайте данные по ссылке\n",
        "data=pd.read_csv(\"/content/titanic.csv\")#\n",
        "print(\"\\n1. Скачали и Загрузили данные:: \" )\n",
        "print(data.head(5)) #|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
        "\n",
        "\n",
        "#2. Исключите признаки, которые на ваш взгляд, могут привести к переобучению (например, id).\n",
        "data.drop([\"PassengerId\", \"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Cabin\",#\"Fare\",\"Embarked\"\n",
        "          ], axis=\"columns\",inplace=True)\n",
        "#print(data.head())\n",
        "\n",
        "X = data.drop([\"Survived\"],axis=\"columns\")\n",
        "Y = data[\"Survived\"]\n",
        "#print(Y)\n",
        "\n",
        "X.Sex = X.Sex.map({\"male\":0,\"female\":1})\n",
        "#print(X.head())\n",
        "#print(X.Age[0:10])\n",
        "\n",
        "X.Age = X.Age.fillna(X.Age.mean())\n",
        "#print(X.Age[0:10])\n",
        "print(\"\\n2. Исключили лишние признаки:: \" )\n",
        "print(X.head()) #|Pclass|Sex|Age|\n",
        "\n",
        "#3. Разделите выборку на train и test.\n",
        "X_train,X_test,Y_train,Y_real=train_test_split(X,Y,train_size = 0.8)\n",
        "print(\"\\n3. Разделили выборку:: \" )\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "#print(X_test)\n",
        "\n",
        "\n",
        "#4. Преобразуйте категориальные признаки с помощью sklearn.preprocessing.OneHotEncoder, \n",
        "#а некатегориальные с помощью sklearn.preprocessing.StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
        "\n",
        "ct = ColumnTransformer([('scaling', StandardScaler(), ['Age', 'Fare']),\n",
        "                       (\"onehot\", OneHotEncoder(sparse=False), ['Sex', 'Pclass', 'Embarked'])])\n",
        "\n",
        "ct.fit(X_train)\n",
        "X_train = ct.transform(X_train)\n",
        "#dfX = pd.DataFrame(X_traint, columns = ['Age', 'Fare','Sex', 'Pclass', 'Embarked'])\n",
        "#print(dfX.head())\n",
        "X_test = ct.transform(X_test)\n",
        "#print(X_testt)\n",
        "print(\"\\n4. Преобразовали категориальные и некатегориальные признаки:: \" )\n",
        "print(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Обучите модель логистической регрессии и посчитайте все метрики классификации\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "model_lr = LogisticRegression(solver='liblinear') #C=100, random_state=SEED\n",
        "model_lr.fit(X_train,Y_train)\n",
        "\n",
        "y_pred_lg = model_lr.predict(X_test)\n",
        "#print(y_pred_lg)\n",
        "\n",
        "print(\"\\n5. Обучили модель логистической регрессии:: \" )\n",
        "print(\"Метрики для модели лог.регрессии:: \" )\n",
        "accuracy_lg = model_lr.score(X_test,Y_real) \n",
        "print(accuracy_lg)\n",
        "\n",
        "acc_lg = metrics.accuracy_score(Y_real,y_pred_lg)\n",
        "print(acc_lg)\n",
        "\n",
        "precision_lg = metrics.precision_score(Y_real,y_pred_lg)  \n",
        "print(precision_lg)\n",
        "\n",
        "rec_lg = metrics.recall_score(Y_real, y_pred_lg)\n",
        "print(rec_lg)\n",
        "\n",
        "cm_lg = metrics.confusion_matrix(Y_real,y_pred_lg)\n",
        "print(cm_lg)\n",
        "\n",
        "auc_lg = metrics.roc_auc_score(Y_real, y_pred_lg)\n",
        "print(auc_lg)\n"
      ],
      "metadata": {
        "id": "U7hXdjQWJEy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490f3deb-5be4-4df3-a6d7-8ae1c94441db"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Обучили модель логистической регрессии:: \n",
            "Метрики для модели лог.регрессии:: \n",
            "0.8044692737430168\n",
            "0.8044692737430168\n",
            "0.7792207792207793\n",
            "0.7692307692307693\n",
            "[[84 17]\n",
            " [18 60]]\n",
            "0.8004569687738005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Обучите модель KNN и посчитайте все метрики классификации\n",
        "#from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "knn_model = KNeighborsClassifier() #(n_neighbors=3,p=2,metric='minkowski'\n",
        "#print(knn_model)\n",
        "\n",
        "knn_model.fit(X_train, Y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "#print(y_pred_knn)\n",
        "\n",
        "print(\"\\n5. Обучили модель KNN:: \" )\n",
        "print(\"Метрики для модели KNN:: \" )\n",
        "rounding = np.round(y_pred_knn)\n",
        "acc_knn = metrics.accuracy_score(Y_real,rounding)  \n",
        "print(acc_knn)\n",
        "\n",
        "precision_knn = metrics.precision_score(Y_real,rounding)  \n",
        "print(precision_knn)\n",
        "\n",
        "recall_knn = metrics.recall_score(Y_real, rounding)\n",
        "print(recall_knn)\n",
        "\n",
        "cm_knn = metrics.confusion_matrix(Y_real, rounding)\n",
        "print(cm_knn)\n",
        "\n",
        "auc_knn = metrics.roc_auc_score(Y_real, rounding)\n",
        "print(auc_knn)\n"
      ],
      "metadata": {
        "id": "AfQFQCShJ-J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce0f137-a9a2-468f-f4b5-c4f1ee3cc0c0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Обучили модель KNN:: \n",
            "Метрики для модели KNN:: \n",
            "0.7932960893854749\n",
            "0.7887323943661971\n",
            "0.717948717948718\n",
            "[[86 15]\n",
            " [22 56]]\n",
            "0.7847169332317847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Подберите гиперпараметры для моделей с помощью RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "knn_params = {\n",
        "    'n_neighbors': [3,5,6,7,10],\n",
        "    'algorithm': ['auto' , 'ball_tree' , 'kd_tree' ,'brute'],\n",
        "    'weights' : ['uniform' , 'distance'],\n",
        "    'leaf_size': [10,20,30,40,50],\n",
        "    'p': [1, 2, 3],\n",
        "    'metric' : ['minkowski','euclidean','manhattan']\n",
        "  }\n",
        "\n",
        "lr_params = {\"penalty\": [\"l1\", \"l2\"],\n",
        "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
        "         \"C\": np.linspace(0.1, 1.0, 50),\n",
        "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
        "\n",
        "rs = RandomizedSearchCV(estimator=knn_model, \n",
        "                        param_distributions=knn_params, \n",
        "                        n_iter=200, \n",
        "                        cv=5, \n",
        "                        verbose=3, \n",
        "                        random_state=0, \n",
        "                        n_jobs=-1)\n",
        "\n",
        "rs.fit(X_train, Y_train)\n",
        "#print(rs.best_score_)\n",
        "#print(rs.best_params_)\n",
        "#bestmodel = rs.best_estimator_\n",
        "print(\"\\n6. Подобрали Наилучшие гиперпараметры для модели KNN:: \" )\n",
        "print(\"Наилучшие гиперпараметры: {}\".format(rs.best_params_))\n",
        "print(\"Лучшее значение кросс-валидации: {:.2%}\".format(rs.best_score_))\n",
        "print(\"Лучшая модель:\\n{}\".format(rs.best_estimator_))\n",
        "\n",
        "\n",
        "#7. Посчитайте метрики для новых моделей, также сделайте выводы.\n",
        "#from sklearn import metrics\n",
        "y_predict = rs.predict(X_test)\n",
        "\n",
        "print(\"\\n7. Посчитали метрики для модели KNN с наилучшими гиперпараметрами:: \" )\n",
        "print(f\"Accuracy: {metrics.accuracy_score(Y_real, y_predict):.4%}\")\n",
        "print(f\"Precision: {metrics.precision_score(Y_real, y_predict):.4%}\")\n",
        "print(f\"Recall: {metrics.recall_score(Y_real, y_predict):.4%}\")\n",
        "print(f\"ROC-AuC Score: {metrics.roc_auc_score(Y_real, rounding):.4%}\")\n",
        "cm = metrics.confusion_matrix(Y_real, y_predict)\n",
        "print(cm)\n",
        "print(f\"F1 Score: {metrics.f1_score(Y_real, y_predict):.4%}\")\n"
      ],
      "metadata": {
        "id": "swxthPUuMIXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9f0392-1131-43d5-b2e2-179f9e0c5481"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
            "\n",
            "6. Подобрали Наилучшие гиперпараметры для модели KNN:: \n",
            "Наилучшие гиперпараметры: {'weights': 'uniform', 'p': 3, 'n_neighbors': 10, 'metric': 'manhattan', 'leaf_size': 50, 'algorithm': 'ball_tree'}\n",
            "Лучшее значение кросс-валидации: 81.32%\n",
            "Лучшая модель:\n",
            "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, metric='manhattan',\n",
            "                     n_neighbors=10, p=3)\n",
            "\n",
            "7. Посчитали метрики для модели KNN с наилучшими гиперпараметрами:: \n",
            "Accuracy: 78.2123%\n",
            "Precision: 85.4545%\n",
            "Recall: 60.2564%\n",
            "ROC-AuC Score: 78.4717%\n",
            "[[93  8]\n",
            " [31 47]]\n",
            "F1 Score: 70.6767%\n"
          ]
        }
      ]
    }
  ]
}